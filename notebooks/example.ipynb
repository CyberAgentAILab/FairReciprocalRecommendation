{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from market import Market\n",
    "from naive import naive\n",
    "from prod import prod\n",
    "from tu_matching import tu_matching\n",
    "from iter_lp import iter_lp\n",
    "from alternate_fw import nsw_maximize, sw_maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a market with 30 left agents and 20 right agents and generate preferencess\n",
    "num_left, num_right = 30, 20\n",
    "m = Market(num_left, num_right)\n",
    "m.generate_preferences(pref_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of matches: 6.097606001793401\n",
      "Number of envies for left agents: 383\n",
      "Number of envies for right agents: 172\n"
     ]
    }
   ],
   "source": [
    "# Naive method\n",
    "stochastic_policy_for_left = naive(m.pref_left_to_right)\n",
    "stochastic_policy_for_right = naive(m.pref_right_to_left)\n",
    "res = m.get_match_prob(\n",
    "    stochastic_policy_for_left=stochastic_policy_for_left,\n",
    "    stochastic_policy_for_right=stochastic_policy_for_right\n",
    ")\n",
    "print(\"Expected number of matches:\", res.sum())\n",
    "\n",
    "envy = m.check_envy(stochastic_policy_for_left=stochastic_policy_for_left, stochastic_policy_for_right=stochastic_policy_for_right, match_prob=res)\n",
    "print(\"Number of envies for left agents:\", len(envy[\"left\"]))\n",
    "print(\"Number of envies for right agents:\", len(envy[\"right\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of matches: 13.214715194901732\n",
      "Number of envies for left agents: 211\n",
      "Number of envies for right agents: 81\n"
     ]
    }
   ],
   "source": [
    "# Prod method\n",
    "stochastic_policy_for_left = prod(m.pref_left_to_right, m.pref_right_to_left)\n",
    "stochastic_policy_for_right = prod(m.pref_right_to_left, m.pref_left_to_right)\n",
    "res = m.get_match_prob(\n",
    "    stochastic_policy_for_left=stochastic_policy_for_left,\n",
    "    stochastic_policy_for_right=stochastic_policy_for_right\n",
    ")\n",
    "print(\"Expected number of matches:\", res.sum())\n",
    "\n",
    "envy = m.check_envy(stochastic_policy_for_left=stochastic_policy_for_left, stochastic_policy_for_right=stochastic_policy_for_right, match_prob=res)\n",
    "print(\"Number of envies for left agents:\", len(envy[\"left\"]))\n",
    "print(\"Number of envies for right agents:\", len(envy[\"right\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of matches: 15.447528483780438\n",
      "Number of envies for left agents: 63\n",
      "Number of envies for right agents: 10\n"
     ]
    }
   ],
   "source": [
    "# TU matching\n",
    "stochastic_policy_for_left, stochastic_policy_for_right = tu_matching(m.pref_left_to_right, m.pref_right_to_left, output=False)\n",
    "res = m.get_match_prob(\n",
    "    stochastic_policy_for_left=stochastic_policy_for_left,\n",
    "    stochastic_policy_for_right=stochastic_policy_for_right\n",
    ")\n",
    "print(\"Expected number of matches:\", res.sum())\n",
    "\n",
    "envy = m.check_envy(stochastic_policy_for_left=stochastic_policy_for_left, stochastic_policy_for_right=stochastic_policy_for_right, match_prob=res)\n",
    "print(\"Number of envies for left agents:\", len(envy[\"left\"]))\n",
    "print(\"Number of envies for right agents:\", len(envy[\"right\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of matches: 15.921955103345166\n",
      "Number of envies for left agents: 103\n",
      "Number of envies for right agents: 0\n"
     ]
    }
   ],
   "source": [
    "# IterLP\n",
    "stochastic_policy_for_left, stochastic_policy_for_right = iter_lp(m.pref_left_to_right, m.pref_right_to_left)\n",
    "res = m.get_match_prob(\n",
    "    stochastic_policy_for_left=stochastic_policy_for_left,\n",
    "    stochastic_policy_for_right=stochastic_policy_for_right\n",
    ")\n",
    "print(\"Expected number of matches:\", res.sum())\n",
    "\n",
    "envy = m.check_envy(stochastic_policy_for_left=stochastic_policy_for_left, stochastic_policy_for_right=stochastic_policy_for_right, match_prob=res)\n",
    "print(\"Number of envies for left agents:\", len(envy[\"left\"]))\n",
    "print(\"Number of envies for right agents:\", len(envy[\"right\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:001  SW:3.98908  UPDATE:3.98908  TIME:0.68607\n",
      "Step:002  SW:4.53201  UPDATE:0.54293  TIME:1.27464\n",
      "Step:003  SW:5.14751  UPDATE:0.61550  TIME:1.92551\n",
      "Step:004  SW:5.80891  UPDATE:0.66140  TIME:2.58041\n",
      "Step:005  SW:6.49300  UPDATE:0.68408  TIME:3.18443\n",
      "Step:006  SW:7.18191  UPDATE:0.68892  TIME:3.82531\n",
      "Step:007  SW:7.86176  UPDATE:0.67985  TIME:4.58188\n",
      "Step:008  SW:8.52231  UPDATE:0.66055  TIME:5.28163\n",
      "Step:009  SW:9.15645  UPDATE:0.63414  TIME:5.93214\n",
      "Step:010  SW:9.75950  UPDATE:0.60305  TIME:6.60173\n",
      "Step:011  SW:10.32854  UPDATE:0.56905  TIME:7.26971\n",
      "Step:012  SW:10.86207  UPDATE:0.53353  TIME:7.96408\n",
      "Step:013  SW:11.35963  UPDATE:0.49756  TIME:8.72461\n",
      "Step:014  SW:11.82154  UPDATE:0.46191  TIME:9.37867\n",
      "Step:015  SW:12.24870  UPDATE:0.42716  TIME:9.94267\n",
      "Step:016  SW:12.64245  UPDATE:0.39375  TIME:10.59905\n",
      "Step:017  SW:13.00437  UPDATE:0.36192  TIME:11.23985\n",
      "Step:018  SW:13.33622  UPDATE:0.33185  TIME:11.83839\n",
      "Step:019  SW:13.63987  UPDATE:0.30364  TIME:12.38005\n",
      "Step:020  SW:13.91720  UPDATE:0.27733  TIME:13.04899\n",
      "Step:021  SW:14.17009  UPDATE:0.25289  TIME:13.81234\n",
      "Step:022  SW:14.40047  UPDATE:0.23038  TIME:14.52034\n",
      "Step:023  SW:14.61010  UPDATE:0.20963  TIME:15.18331\n",
      "Step:024  SW:14.80064  UPDATE:0.19054  TIME:15.93831\n",
      "Step:025  SW:14.97365  UPDATE:0.17301  TIME:16.65847\n",
      "Step:026  SW:15.13060  UPDATE:0.15695  TIME:17.26108\n",
      "Step:027  SW:15.27286  UPDATE:0.14226  TIME:17.96254\n",
      "Step:028  SW:15.40171  UPDATE:0.12885  TIME:18.66471\n",
      "Step:029  SW:15.51835  UPDATE:0.11663  TIME:19.26005\n",
      "Step:030  SW:15.62385  UPDATE:0.10551  TIME:19.92473\n",
      "Step:031  SW:15.71925  UPDATE:0.09540  TIME:20.53406\n",
      "Step:032  SW:15.80547  UPDATE:0.08622  TIME:21.11276\n",
      "Step:033  SW:15.88337  UPDATE:0.07789  TIME:21.64099\n",
      "Step:034  SW:15.95371  UPDATE:0.07035  TIME:22.26942\n",
      "Step:035  SW:16.01722  UPDATE:0.06351  TIME:22.95570\n",
      "Step:036  SW:16.07454  UPDATE:0.05732  TIME:23.54852\n",
      "Step:037  SW:16.12626  UPDATE:0.05172  TIME:24.06982\n",
      "Step:038  SW:16.17293  UPDATE:0.04666  TIME:24.65677\n",
      "Step:039  SW:16.21501  UPDATE:0.04209  TIME:25.26778\n",
      "Step:040  SW:16.25296  UPDATE:0.03795  TIME:26.00270\n",
      "Step:041  SW:16.28718  UPDATE:0.03422  TIME:26.65823\n",
      "Step:042  SW:16.31803  UPDATE:0.03085  TIME:27.19133\n",
      "Step:043  SW:16.34583  UPDATE:0.02780  TIME:27.71618\n",
      "Step:044  SW:16.37089  UPDATE:0.02506  TIME:28.22313\n",
      "Step:045  SW:16.39347  UPDATE:0.02258  TIME:28.73835\n",
      "Step:046  SW:16.41381  UPDATE:0.02034  TIME:29.30216\n",
      "Step:047  SW:16.43214  UPDATE:0.01833  TIME:29.96001\n",
      "Step:048  SW:16.44865  UPDATE:0.01651  TIME:30.62521\n",
      "Step:049  SW:16.46352  UPDATE:0.01487  TIME:31.12896\n",
      "Step:050  SW:16.47692  UPDATE:0.01340  TIME:31.66656\n",
      "Step:051  SW:16.48898  UPDATE:0.01206  TIME:32.32167\n",
      "Step:052  SW:16.49985  UPDATE:0.01087  TIME:33.02115\n",
      "Step:053  SW:16.50963  UPDATE:0.00979  TIME:33.61336\n",
      "Converged in 53 iterations.\n",
      "Expected number of matches: 16.50963328734808\n",
      "Number of envies for left agents: 28\n",
      "Number of envies for right agents: 7\n"
     ]
    }
   ],
   "source": [
    "# SW maximization\n",
    "stochastic_policy_for_left, stochastic_policy_for_right = sw_maximize(m.pref_left_to_right, m.pref_right_to_left, v_left=m.v_left, v_right=m.v_right)\n",
    "res = m.get_match_prob(\n",
    "    stochastic_policy_for_left=stochastic_policy_for_left,\n",
    "    stochastic_policy_for_right=stochastic_policy_for_right\n",
    ")\n",
    "print(\"Expected number of matches:\", res.sum())\n",
    "\n",
    "envy = m.check_envy(stochastic_policy_for_left=stochastic_policy_for_left, stochastic_policy_for_right=stochastic_policy_for_right, match_prob=res)\n",
    "print(\"Number of envies for left agents:\", len(envy[\"left\"]))\n",
    "print(\"Number of envies for right agents:\", len(envy[\"right\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:001  SW:3.89666  UPDATE:3.89666  TIME:0.75037\n",
      "Step:002  SW:4.38332  UPDATE:0.48666  TIME:1.51615\n",
      "Step:003  SW:4.96279  UPDATE:0.57947  TIME:2.30266\n",
      "Step:004  SW:5.59111  UPDATE:0.62832  TIME:3.06587\n",
      "Step:005  SW:6.26409  UPDATE:0.67297  TIME:3.80547\n",
      "Step:006  SW:6.91372  UPDATE:0.64963  TIME:4.56426\n",
      "Step:007  SW:7.57720  UPDATE:0.66348  TIME:5.38869\n",
      "Step:008  SW:8.20338  UPDATE:0.62618  TIME:6.07692\n",
      "Step:009  SW:8.83494  UPDATE:0.63156  TIME:6.70591\n",
      "Step:010  SW:9.40248  UPDATE:0.56754  TIME:7.53307\n",
      "Step:011  SW:9.96476  UPDATE:0.56229  TIME:8.20403\n",
      "Step:012  SW:10.46680  UPDATE:0.50204  TIME:8.88756\n",
      "Step:013  SW:10.96721  UPDATE:0.50041  TIME:9.51465\n",
      "Step:014  SW:11.41177  UPDATE:0.44456  TIME:10.29213\n",
      "Step:015  SW:11.81967  UPDATE:0.40791  TIME:11.05666\n",
      "Step:016  SW:12.20399  UPDATE:0.38431  TIME:11.78110\n",
      "Step:017  SW:12.55896  UPDATE:0.35497  TIME:12.59357\n",
      "Step:018  SW:12.89252  UPDATE:0.33356  TIME:13.37713\n",
      "Step:019  SW:13.18408  UPDATE:0.29156  TIME:14.14324\n",
      "Step:020  SW:13.44094  UPDATE:0.25686  TIME:14.91941\n",
      "Step:021  SW:13.68953  UPDATE:0.24859  TIME:15.61307\n",
      "Step:022  SW:13.92450  UPDATE:0.23497  TIME:16.31865\n",
      "Step:023  SW:14.12113  UPDATE:0.19663  TIME:17.05628\n",
      "Step:024  SW:14.31403  UPDATE:0.19289  TIME:17.81874\n",
      "Step:025  SW:14.47425  UPDATE:0.16023  TIME:18.56338\n",
      "Step:026  SW:14.61916  UPDATE:0.14491  TIME:19.33314\n",
      "Step:027  SW:14.75163  UPDATE:0.13246  TIME:20.06013\n",
      "Step:028  SW:14.89190  UPDATE:0.14027  TIME:20.78687\n",
      "Step:029  SW:14.99153  UPDATE:0.09963  TIME:21.39189\n",
      "Step:030  SW:15.09899  UPDATE:0.10746  TIME:22.10920\n",
      "Step:031  SW:15.19294  UPDATE:0.09395  TIME:22.71120\n",
      "Step:032  SW:15.28037  UPDATE:0.08744  TIME:23.31757\n",
      "Step:033  SW:15.35435  UPDATE:0.07398  TIME:23.92086\n",
      "Step:034  SW:15.42099  UPDATE:0.06664  TIME:24.53076\n",
      "Step:035  SW:15.48120  UPDATE:0.06021  TIME:25.21004\n",
      "Step:036  SW:15.54555  UPDATE:0.06435  TIME:25.80984\n",
      "Step:037  SW:15.58207  UPDATE:0.03653  TIME:26.44028\n",
      "Step:038  SW:15.63102  UPDATE:0.04895  TIME:27.01908\n",
      "Step:039  SW:15.67777  UPDATE:0.04675  TIME:27.71286\n",
      "Step:040  SW:15.70126  UPDATE:0.02349  TIME:28.34910\n",
      "Step:041  SW:15.75972  UPDATE:0.05846  TIME:28.98937\n",
      "Step:042  SW:15.76227  UPDATE:0.00255  TIME:29.56371\n",
      "Converged in 42 iterations.\n",
      "Expected number of matches: 15.762271452010395\n",
      "Number of envies for left agents: 0\n",
      "Number of envies for right agents: 0\n"
     ]
    }
   ],
   "source": [
    "# NSW maximization\n",
    "stochastic_policy_for_left, stochastic_policy_for_right = nsw_maximize(m.pref_left_to_right, m.pref_right_to_left, v_left=m.v_left, v_right=m.v_right)\n",
    "res = m.get_match_prob(\n",
    "    stochastic_policy_for_left=stochastic_policy_for_left,\n",
    "    stochastic_policy_for_right=stochastic_policy_for_right\n",
    ")\n",
    "print(\"Expected number of matches:\", res.sum())\n",
    "\n",
    "envy = m.check_envy(stochastic_policy_for_left=stochastic_policy_for_left, stochastic_policy_for_right=stochastic_policy_for_right, match_prob=res)\n",
    "print(\"Number of envies for left agents:\", len(envy[\"left\"]))\n",
    "print(\"Number of envies for right agents:\", len(envy[\"right\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
